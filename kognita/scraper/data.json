{"question": {"question_title": "How to get histogram data using from a 2D NumPy array?", "question_text": "\n                    \nCan numpy.histogram() process a 2D NumPy array? I can't seem to get it to work? In the example below, I am expecting the numpy.histogram() function to return a 3x2 where the 2 denotes a tuple with 2 1D numpy array of size 20 contain the necessary count and bins data, respectively.\nExample\n>>> import numpy as np\n>>> from numpy.random import default_rng\n>>> from scipy.stats import norm\n>>> rg = default_rng()\n>>> a = norm.rvs( size=(3, 100), random_state=rg )\n>>> np.histogram( a, bins=20 )\n(array([ 2,  2,  4,  6, 10, 11, 15, 19, 37, 26, 25, 28, 27, 29, 21, 22,  5,\n        5,  3,  3]), array([-2.736423  , -2.47271089, -2.20899879, -1.94528668, -1.68157457,\n       -1.41786247, -1.15415036, -0.89043825, -0.62672615, -0.36301404,\n       -0.09930193,  0.16441017,  0.42812228,  0.69183439,  0.95554649,\n        1.2192586 ,  1.48297071,  1.74668281,  2.01039492,  2.27410703,\n        2.53781913]))\n>>> np.histogram( a.T, bins=20 )\n(array([ 2,  2,  4,  6, 10, 11, 15, 19, 37, 26, 25, 28, 27, 29, 21, 22,  5,\n        5,  3,  3]), array([-2.736423  , -2.47271089, -2.20899879, -1.94528668, -1.68157457,\n       -1.41786247, -1.15415036, -0.89043825, -0.62672615, -0.36301404,\n       -0.09930193,  0.16441017,  0.42812228,  0.69183439,  0.95554649,\n        1.2192586 ,  1.48297071,  1.74668281,  2.01039492,  2.27410703,\n        2.53781913]))\n    ", "question_tags": ["python", "numpy"], "question_date": "3 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Django Page not found, The current path, didn't match any of these", "question_text": "\n                    \nI have created a new template in my app menus.html\nThe index path is working fine but when I added a new template that path is not working. Below is my url code in app\nurlpatterns = [\n    path('', views.index, name='index'),\n    # url(r'^resto/menus/$', views.menus, name='menus')\n    path('menu/', views.menus, name='menus'),\n]\nThe path specified in first line is working fine. I want to add a new view to the path (views.menus)\nBelow is my urls.py from main app\nurlpatterns = [\n    path('admin/', admin.site.urls),\n    path('resto/', include('resto.urls'))\n]\nMy menus.html file\ndef menus(request):\n    return HttpResponse(\"Test\")\nI tried restarting the server but not worked,\nI am accessing this url http://localhost:8000/menus/\n\n    \nYour app (resto app) urls are wired to /resto/ path and thus any path on your app will be prefixed with /resto/.\nSo, you need to call /resto/menu/ to access the views.menus view.\n    ", "question_tags": ["python", "django", "url", "url-pattern"], "question_date": "3 mins ago", "question_comments": [], "all_answer": [{"answer_text": "\nYour app (resto app) urls are wired to /resto/ path and thus any path on your app will be prefixed with /resto/.\nSo, you need to call /resto/menu/ to access the views.menus view.\n    ", "answer_user": "", "answer_date": "3 mins ago", "answer_comments": [], "answer_use": "Arakkal Abu"}]}}{"question": {"question_title": "How can I pass a parameter using numpy.vectorize", "question_text": "\n                    \nI have been trying to use numpy with objects and to run the functions I have been trying to use the numpy.vectorize function and it works great but I don't know how to pass parameters through the code for example\nimport numpy as np\nclass ex:\n   def __init__(self, a, b):\n       self.a = a\n       self.b = b\n\n   def exfunc(self, c):\n       print(c)\n\nstr = \"hi\"\nlis =np.array([ex() for x in range(10)])    \nexvec = np.vectorize(ex.exfunc, otypes=[object])\n\nnow i dont know how this would be done but I would like to be able to pass a pram like this exvec(lis,str) but this doesn't work so I would to know how I can do something similar to what I just shown Thanks in advance\n    ", "question_tags": ["python", "numpy"], "question_date": "8 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Image Augmentation with target", "question_text": "\n                    \nGuys please I need answers to this. I augmented some images, these images have labels(class). These my augmented images should have new targets. How do I locate these new labels if they are generated(have in mind these targets/labels are csv files)... And if they are not generated, do I manually perform augmentation on them?if yes, how?\n    ", "question_tags": ["python", "machine-learning"], "question_date": "9 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Parsing a date with no leading zeros, no space, and no backlash", "question_text": "\n                    \nHi I have a string like this: \"202082201\", which means 2020/8/2 20:01.\nThis is because every field in the string doesn't have any leading zero.\nThe task is to turn this string into a date in python. I've tried this code:\nregex ='%Y%m%d%H%M'\nstr = \"202082201\"\ndate_obj = dt.strptime(str, regex)\ndate_str = dt.strftime(date_obj, '%Y/%m/%d %H:%M')\nprint(date_str)\nBut it gives me 2020/08/22 00:01 instead.\n    \nI think your best bet is to create a custom function to call instead of strftime(). Have it take in a datetime object and then spit out the custom string you need.\n    ", "question_tags": ["python", "datetime", "leading-zero"], "question_date": "2 mins ago", "question_comments": [{"text": "According to the ", "author": "metatoaster", "date": "3 mins ago"}, {"text": "According to the ", "author": "metatoaster", "date": "3 mins ago"}], "all_answer": [{"answer_text": "\nI think your best bet is to create a custom function to call instead of strftime(). Have it take in a datetime object and then spit out the custom string you need.\n    ", "answer_user": "", "answer_date": "2 mins ago", "answer_comments": [], "answer_use": "Randy Maldonado"}]}}{"question": {"question_title": "using the re.sub not able to get expected output", "question_text": "\n                    \na=[\"Log check\",\"(check log:[{Table\n|AllianceCarEnergyManager: AllianceEnergyEventListenerToService onEvent: Event type: 2~, Event id: 1~, Event value: 0}]\"]\np=[re.sub(\"\\[{Table:+\\w*}]\", \")\") for i in range(len(a)) if a[i] != \"\"]\nprint(p)\nRequired output:[\"Log check\",\"(check log:\nAllianceCarEnergyManager: AllianceEnergyEventListenerToService onEvent: Event type: 2~, Event id: 1~, Event value: 0\"]\n    ", "question_tags": ["python", "regex", "list"], "question_date": "14 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Selenium bringing up wrong element by xpath even though the path is correct", "question_text": "\n                    \nI have been making a simple selenium script using python.\nfrom selenium.webdriver.support.ui import Select\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nimport time\nimport string \nimport random \n# initializing size of string  \na = 1\nwhile a==1:\n    N = 7\n      \n    # using random.choices() \n    # generating random strings  \n    res = ''.join(random.choices(string.ascii_uppercase +\n                                 string.digits, k = N)) \n      \n    \n    options = webdriver.ChromeOptions() \n    options.add_argument(\"start-maximized\")\n    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n    options.add_experimental_option('useAutomationExtension', False)\n    \n    driver=webdriver.Chrome(options=options)\n    driver.get(\"https://www.wattpad.com/login\")\n    signup=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[3]/div/div[2]/main/div/div/div/footer/span/button\")\n    signup.click()\n    button=driver.find_element_by_xpath (\"/html/body/div[3]/div/div[3]/div/div[2]/main/div/div/div/div/div/button\")\n    button.click()\n    username=driver.find_element_by_id (\"signup-username\")\n    username.send_keys(str(res))\n\n\n    second_tab = webdriver.Chrome(options=options,)\n\n    second_tab.get(\"https://www.fakemail.net/\")\n    randombutton = second_tab.find_element_by_xpath(\"//div[2]/div/a\") #for the email generation\n    time.sleep(2)\n    emailentry = second_tab.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/span[1]\").text\n    print (\"your email is \" + emailentry)\n\n    emailspace = driver.find_element_by_id (\"signup-email\")\n    emailspace.send_keys(emailentry)\n    password = driver.find_element_by_id (\"signup-password\")\n    password.send_keys (\"subscribe\")\n    driver.find_element_by_xpath(\"//select[@id='signup-month']/option[text()='Nov']\").click()\n    driver.find_element_by_xpath(\"//select[@id='signup-day']/option[text()='18']\").click()\n    driver.find_element_by_xpath(\"//select[@id='signup-year']/option[text()='1996']\").click()\n    submitbutton=driver.find_element_by_xpath(\"//input[@value='Sign up with email']\").click()\n    print(\"acount maker done\")\n\n    with open(r\"C:\\Users\\BRS\\Desktop\\wattpad.txt\", 'a',encoding = \"utf-8\") as outfile:\n        outfile.write(emailentry)\n\n    outfile.close()    \n\n    time.sleep(10)\n\n\n\n\n    WebDriverWait(second_tab, 90).until(EC.element_to_be_clickable((By.XPATH, \"//tbody[@id='schranka']/tr/td\"))).click()\n    time.sleep(2)\n    linky= second_tab.find_element_by_xpath(\"//a[contains(text(),'This is me!')]\").get_attribute('href')\n    second_tab.get(linky)\n\n\n\n\n\n    '''verilink= input(\"enter the verification link:\\n\")\n    driver.get(verilink)'''\n    time.sleep(5)\n    driver.get(\"https://www.wattpad.com/893851831-my-2nd-year-chapter-1\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n    driver.get(\"https://www.wattpad.com/893856960-my-2nd-year-chapter-2-10-minutes-later\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/894447654-my-2nd-year-chapter-3\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/895034288-my-2nd-year-chapter-4-6-hours-later\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/896648779-my-2nd-year-chapter-5-after-1-week\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/897330154-my-2nd-year-specials-chapter-6\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/898580167-my-2nd-year-chapter-7\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/899494005-my-2nd-year-chapter-8\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n\n    driver.get(\"https://www.wattpad.com/901463787-my-2nd-year-chapter-9\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n    driver.get(\"https://www.wattpad.com/902498234-my-2nd-year-after-an-hour-chapter-10\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n    driver.get(\"https://www.wattpad.com/918598116-my-2nd-year-chapter-11\")\n    vote1=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[1]/div/div[2]/div[2]/button/span[2]\")\n    vote1.click()\n\n    print(\"Done added 11 votes\")\n    time.sleep(5)\n    driver.quit()\n    second_tab.quit()\neverything was working fine untill one random day i started getting this problem\nFile \"C:\\Users\\BRS\\Desktop\\AccountChef\\wattpad acc maker - Copy.py\", line 66, in <module>\n    linky= second_tab.find_element_by_xpath(\"//a[contains(text(),'This is me!')]\").get_attribute('href')\n  File \"C:\\Users\\BRS\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 394, in find_element_by_xpath\n    return self.find_element(by=By.XPATH, value=xpath)\n  File \"C:\\Users\\BRS\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 976, in find_element\n    return self.execute(Command.FIND_ELEMENT, {\n  File \"C:\\Users\\BRS\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n    self.error_handler.check_response(response)\n  File \"C:\\Users\\BRS\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n    raise exception_class(message, screen, stacktrace)\nselenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[contains(text(),'This is me!')]\"}\ntrust me i tried every type of selector but somehow this is always missed by the webdriver and i encounter an error. the button i get error on contains text \"This is me!\".\n    ", "question_tags": ["python", "selenium", "selenium-webdriver", "selenium-chromedriver"], "question_date": "19 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "how to convert tensorflow.pbtxt model to .bytes for unity?", "question_text": "\n                    \nI am trying to convert a CNN regression model with python TensorFlow to a format to use in unity. Unity works with models in (.bytes) format.\nI was using this code but it just saves the graph and converts it to (.pbtxt).\n     sess = tf.Session()\n     init = tf.global_variables_initializer()\n     sess.run(init)\n     saver = tf.train.Saver()\n     tf.train.write_graph(sess.graph_def, '.', 'pose.pbtxt')  \n     saver.save(sess, 'pose.ckpt')\nThen, does exist any method to overcome this issue?\n    ", "question_tags": ["python", "tensorflow", "unity3d"], "question_date": "20 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Create multiple conda environments inside a single dockerfile", "question_text": "\n                    \nI am new to the docker concepts .Now I want to create multiple conda environments ,Each one will have its own python app. Now I want to put all of these environments inside one single docker file using same base image of miniconda .\nMy question is ,is this possible? If so,then how to proceed with that , a little example will be really appreciated.\n    ", "question_tags": ["python", "docker", "dockerfile", "miniconda"], "question_date": "20 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "how to use flask-ask without using ngrok", "question_text": "\n                    \nokay so I'm really inexperienced with all this so bear with me if this is a dumb question.\nSo I'm planning out a raspberry pi that can turn my computer off and on with alexa commands. So far the best candidate I've found so far is flask-ask. My only issue with it is that it seems to rely on ngrok, and since I want to have this as a permanent part of my computer, I would have to buy at least the basic tier so I could have a static url. I would rather not do this as 60 dollars a year is a bit more than I am willing to pay for something like this. What I want to know is if and how I can use flask-ask with ngrok alternatives like localtunnel or something else along those lines.\n    ", "question_tags": ["python", "raspberry-pi", "alexa", "flask-ask"], "question_date": "23 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "How do I get a list of all the categories and channels inside the current server with discord.py in discord?", "question_text": "\n                    \nI want an output that will output all the (category names and ids + channel names and ids)inside the server that the bot is in.\nThe code might look something like this:\n# catetories\n@client.command()\nasync def list_catetories(ctx):\n  for category in discord.categories:\n    print('id: ' + category.id + ', name: ' + category.name)\n\n# channels\n@client.command()\nasync def channels(ctx):\n  for channel in discord.channels:\n    print('id: ' + channel.id + ', name: ' + channel.name)\n    ", "question_tags": ["python", "python-3.x", "discord", "discord.py"], "question_date": "26 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Is this a correct approach for Linear Regression with only 205 observations and 60 features including dummy variables?", "question_text": "\n                        \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question was migrated from Stack Overflow because it can be answered on Cross Validated.\n                        Migrated 16 mins ago.\n                    \n                \n            \n        \n\n\n    \n\nIs this a correct approach for Linear Regression with only 205 observations and 60 features including dummy variables?\nThe following is what I have tried out so far. Tried 50+ different models with Recursive Feature Elimination (RFE) plus manual elimination methodologies. The following are my hard-learned observations.\n\nRFE auto eliminates some meaningful and impactful features with we are having no control over the process. Even if you shortlist it to 15 features, eliminated good ones.\n\nAfter this shortlisting, if you apply manual step-by-step elimination using p-values first and then using VIF values, finally you are just left with the features that hardly have any domain importance \u2013 kind of junk ones.\n\nI repeated steps 1 and 2 multiple times \u2013 each time choosing a different number with RFE, the results are almost the same. So finally, I found it a junk and useless process for any meaningful model building.\n\nEvery time I did steps 1 to 3, I got good r2 for the train but very little r2 for test. That means the model is overfitting each time.\n\nThis overfitting is simply because the number of features after putting dummy ones is more and at the same time, the number of observations is only 205. So, the model is memorizing all these observations and getting overfitted each time.\n\nThen I consulted one of my friends who is an expert for the car pricing in for the Indian market and asked him to choose the most important features (from the business angle) that really impact the car pricing in the Indian markets. Note, the US market is different. So I made a superset that may include all the features covering Indian and the US markets.\n\nWith this feature superset, I repeated steps 1 and 2. Got good r2 on the train but very less on the train. This means the model again overfitted as the total number of observations is just too tiny. The model is memorizing everything in place of finding general trends.\n\nAt this stage, I would like to refer you to some Industry Experts. In problems where the number of observations that were tiny, they decide not to do a train test split and utilize the entire dataset in one shot for the model building. They argue that with such a low number of observations, a test-train split would be a luxury.\n\nThen I took the approach of step 8 and repeated step 6 again on the entire dataset with 205 observations. Note that this time RFE is not used. All the features in the first model are the ones suggested as meaningful by a domain expert. Then I applied usual p-value and VIF based eliminations and got a good r2 with all meaningful variables (from a domain point of view) only left as the final features.\n\nThe final model and the set of features I got from step 9 is the best model of all 50+ models that I have tried out so far with various methodologies and different sets of starting feature set. Note that a train-test split is not done here and the entire dataset is used to build the model.\n\nI referred to Andrew Ng\u2019s approach from one of the Coursera\u2019s online courses, there also he suggests to manually select the initial set of features for your first model and then do manual elimination one by one based on p-values and VIFs. It\u2019s all to avoid overfitting and to get meaningful variables only that would make sense to the business.\n\nHaving said that, I want your opinions as well. If you have done a train-test split is your r2 in the train is matching to that of r2 in the test as well? What is your opinion of this overfitting challenge in the light of this assignment?\n\n\nIs this a correct approach? What are the merits and demerits? Can you suggest a better approach?\n    \n@ Ben Bolker: Yes! Step 9 the good r^2 you refer to is a within-sample r^2...\n    ", "question_tags": ["python", "r"], "question_date": "7 mins ago", "question_comments": [{"text": "60-205 does not sound good. But ok, let's ignore this. So RFE/p-value based elimination is in many cases a bad idea, especially if you have multi-coll and feature correlation. Did you check for this? VIF is much more stable. But I'd recommend going directly with Ridge, Lasso, ElasticNet, as proposed by @BenBolker , possibly prepending a PCA.", "author": "Scotty1-", "date": "19 mins ago"}, {"text": "Note also that in this scenario ", "author": "Ben Bolker", "date": "17 mins ago"}, {"text": "Is it true that in step 9 the good r^2 you refer to is a within-sample r^2 (because you don't have a separate test set)? If so, then you probably don't really have a good model; you just can't estimate the degree of overfitting because you don't have a test set to evaluate on. You can use something like 10-fold cross-validation to get a sense of the out-of-sample error without compromising the size of the data set too much.", "author": "Ben Bolker", "date": "11 mins ago"}, {"text": "60-205 does not sound good. But ok, let's ignore this. So RFE/p-value based elimination is in many cases a bad idea, especially if you have multi-coll and feature correlation. Did you check for this? VIF is much more stable. But I'd recommend going directly with Ridge, Lasso, ElasticNet, as proposed by @BenBolker , possibly prepending a PCA.", "author": "Scotty1-", "date": "19 mins ago"}, {"text": "Note also that in this scenario ", "author": "Ben Bolker", "date": "17 mins ago"}, {"text": "Is it true that in step 9 the good r^2 you refer to is a within-sample r^2 (because you don't have a separate test set)? If so, then you probably don't really have a good model; you just can't estimate the degree of overfitting because you don't have a test set to evaluate on. You can use something like 10-fold cross-validation to get a sense of the out-of-sample error without compromising the size of the data set too much.", "author": "Ben Bolker", "date": "11 mins ago"}], "all_answer": [{"answer_text": "\n@ Ben Bolker: Yes! Step 9 the good r^2 you refer to is a within-sample r^2...\n    ", "answer_user": "", "answer_date": "7 mins ago", "answer_comments": [], "answer_use": "Shailendra Kadre"}]}}{"question": {"question_title": "How can i extract the email address string", "question_text": "\n                    \nMy python script currently pulls an email addresses as a list, but I need to get the text portion only. In this example, it should have been golfshop@3lakesgolf.com. I have tried using the text attribute (gc_email.text) but that didn't work.\ngc_email=web.select('a[href^=mailto]')\nprint(gc_email)\noutput:\n[<a href=\"mailto:golfshop@3lakesgolf.com\">golfshop@3lakesgolf.com</a>] \nHelp! Howcan I extract just the mailto address?\n    \nYou can use a regex capture to pull this string\nimport re\n\nstr = '<a href=\"mailto:golfshop@3lakesgolf.com\">golfshop@3lakesgolf.com</a>'\nregex = '<a href=\"mailto:(.*?)\".*'\n\ntry:\n    match = re.match(regex, str).group(1)\nexcept:\n    match = None\n    x=1\n\nif match is not None:\n    print(match)\n    \nOutput\ngolfshop@3lakesgolf.com\n    ", "question_tags": ["python"], "question_date": "24 mins ago", "question_comments": [], "all_answer": [{"answer_text": "\nYou can use a regex capture to pull this string\nimport re\n\nstr = '<a href=\"mailto:golfshop@3lakesgolf.com\">golfshop@3lakesgolf.com</a>'\nregex = '<a href=\"mailto:(.*?)\".*'\n\ntry:\n    match = re.match(regex, str).group(1)\nexcept:\n    match = None\n    x=1\n\nif match is not None:\n    print(match)\n    \nOutput\ngolfshop@3lakesgolf.com\n    ", "answer_user": "", "answer_date": "24 mins ago", "answer_comments": [], "answer_use": "Pulsar"}]}}{"question": {"question_title": "python problem will not run need help fixing the problem?", "question_text": "\n                    \ndef main():\n\n    input_val: name1 = int(input('Enter purchase items: '))\n    input_val: name2 = int(input('Enter purchase items: '))\n    input_val: name3 = int(input('Enter purchase items: '))\n    if input_val <= 0:\n        print('Some error message')\n    else:\n        num_discount1 = input_val // 10\n        input_val %= 10\n        num_discount2 = input_val // 15\n        input_val %= 15\n        num_discount3 = input_val // 20\n        input_val %= 20\n        name1 = num_discount1\n        name2 = num_discount2\n        name3 = num_discount3\n\n\nif name1 is num_discount1:\n    print('Found', name, 'total gbyte to purchase. ')\n\nelse:\n    print(\"Could not find', name\")\n\nif name2 is num_discount2:\n    print('Found', name, 'total gbyte to purchase. ')\n\nelse:\n    print(\"'Could not find',name\")\n\nif name3 is num_discount3:\n    print('Found', name, 'total gbyte to purchase. ')\n\nelse:\n    print(\"'Could not find', name\")\n    \nWhen I try to run your program, I get the following traceback:\n  File \"wontrun.py\", line 3\n    input_val: name1 = int(input('Enter purchase items: '))\n             ^\nSyntaxError: invalid syntax\nPLEASE DO NOT UPVOTE THIS OR ACCEPT THIS ANSWER\n    ", "question_tags": ["python"], "question_date": "20 mins ago", "question_comments": [{"text": "Welcome to Stack Overflow. How exactly did you try to run the program? What happened when you tried to run the program, and how is that different from what should happen?", "author": "Karl Knechtel", "date": "28 mins ago"}, {"text": "@Scottie Could you add more information about what are you trying to do? what was the problem? what was the error message?", "author": "Rushikesh Gaidhani", "date": "26 mins ago"}, {"text": " is invalid syntax. This question should be closed.", "author": "David Cullen", "date": "21 mins ago"}, {"text": "Welcome to Stack Overflow. How exactly did you try to run the program? What happened when you tried to run the program, and how is that different from what should happen?", "author": "Karl Knechtel", "date": "28 mins ago"}, {"text": "@Scottie Could you add more information about what are you trying to do? what was the problem? what was the error message?", "author": "Rushikesh Gaidhani", "date": "26 mins ago"}, {"text": " is invalid syntax. This question should be closed.", "author": "David Cullen", "date": "21 mins ago"}], "all_answer": [{"answer_text": "\nWhen I try to run your program, I get the following traceback:\n  File \"wontrun.py\", line 3\n    input_val: name1 = int(input('Enter purchase items: '))\n             ^\nSyntaxError: invalid syntax\nPLEASE DO NOT UPVOTE THIS OR ACCEPT THIS ANSWER\n    ", "answer_user": "", "answer_date": "20 mins ago", "answer_comments": [], "answer_use": "David Cullen"}]}}{"question": {"question_title": "Player Keeps Sticking On The Platform Collision Pygame", "question_text": "\n                    \nI am trying to get a good collision with my rectangles but I feel like my method is bad because when ever I job and collide  with my other platform my player keeps getting stuck on it, is there  a way I could make it collide good without it getting stuck I am just looking for a good collision Thank You!\nVIDEO < as you can see my player keeps getting stuck on the platform its the same thing for left and right when I collide with the platform it will just make my player stuck without proper collision\n        # collisions\n        for platform in platforms:\n            if playerman.rect.colliderect(platform.rect):\n                collide = True\n                playerman.isJump = False\n                if (platform.rect.collidepoint(playerman.rect.right, playerman.rect.bottom) or\n                    platform.rect.collidepoint(playerman.rect.left, playerman.rect.bottom)):\n                    playerman.y = platform.rect.top - playerman.height + 1\n                    playerman.moveright = True\n                    playerman.moveleft = True\n                \n                if (platform.rect.collidepoint(playerman.rect.right, playerman.rect.top) or\n                    platform.rect.collidepoint(playerman.rect.right, playerman.rect.bottom - 10)):\n                    playerman.moveright = False\n                elif (platform.rect.collidepoint(playerman.rect.left, playerman.rect.top) or\n                      platform.rect.collidepoint(playerman.rect.left, playerman.rect.bottom - 10)):\n                    playerman.moveleft = False\n            else:\n                playerman.moveright = True\n                playerman.moveleft = True\n                \n\n\nmy full code:  script\nI been searching everywhere for proper collision and I cant manage to find any good working ones\n    ", "question_tags": ["python", "pygame"], "question_date": "35 mins ago", "question_comments": [{"text": "Maybe you can check for collision when you are changing the ", "author": "Kingsley", "date": "25 mins ago"}], "all_answer": []}}{"question": {"question_title": "Python Pyaudio + Microphone + Filter in real time", "question_text": "\n                    \nI am working on a project in which I need to follow three prerequisites.\n\nUse the microphone for real-time recording.\nListen to the microphone at the computer's Speaker output in real time.\nDo a modification to this stream by performing a bandpass filter during the execution of the streaming.\n\nI still couldn't find any example for manipulating the audio during the execution in a callback, I believe that this process is blocked for possible manipulations. I am not a python expert. Could someone give me a direction?\nAt the moment I already have the microphone available to hear when starting the script.\n# -*- coding: utf-8 -*- \n\nimport pyaudio\n\nFORMATO = pyaudio.paInt16 # Pode ser pyaudio.paFloat32 tamb\u00e9m\nCHUNK = 1024\nWIDTH = 2\nCANAL = 1\nRATE = 44100\nFRAMESWAV = []\np = pyaudio.PyAudio()\n\n\ndef loopback(in_data, frame_count, time_info, status):                      \n    return (in_data, pyaudio.paContinue)\n            \n\n\n# Abrindo Canal para ouvir o microfone.          \nstream = p.open(format=p.get_format_from_width(WIDTH), channels=CANAL, rate=RATE, \n            input=True, \n            output=True, \n            frames_per_buffer=CHUNK,\n            stream_callback=loopback)\n\nstream.start_stream()   \n\nwhile True:    \n    \n    i = input(\"Pressione Enter SAIR\")\n    if not i:    \n        stream.stop_stream()\n        stream.close()        \n        p.terminate()        \n        print(\"Voce pressionou para SAIR.\")\n        break\n    else:   \n        continue\n    ", "question_tags": ["python"], "question_date": "36 mins ago", "question_comments": [], "all_answer": []}}{"question": {"question_title": "Issue of Beautifulsoup in Python", "question_text": "\n                    \ni'm a beginner of Python. I would like to scrape those information such as Name, Constituency, Education and professional qualifications, Occupation, Political affiliation, Office address, Office telephone and E-mail from this website:\nhttps://www.legco.gov.hk/general/english/members/yr16-20/lky.htm\nHowever, i just only scrape the name on this website. How can i finish the requirements? Here is my coding:\nimport requests\nfrom bs4 import BeautifulSoup\nr = requests.get(\"https://www.legco.gov.hk/general/chinese/members/yr16-20/biographies.htm\")\nsoup = BeautifulSoup(r.text,'html.parser')\nfor anchor in soup.find_all('a'):\n    href = anchor.get('href', '/')\n    if href.startswith(\"lky\"):\n      href = \"https://www.legco.gov.hk/general/english/members/yr16-20/\" + href\n      print(href)\n      r2 = requests.get(href)\n      #print(r2.text)\n      detail_soup = BeautifulSoup(r2.text,'html.parser')\n      name = detail_soup.find(\"h2\")\n      print(name.text.strip())\n      break\nprint(\"End of loop\")\nThank you so much!!\n    ", "question_tags": ["python", "web-scraping", "beautifulsoup"], "question_date": "40 mins ago", "question_comments": [{"text": "likely you're to learn Python (in general) & BeautifulSoup (in particular) to understand what and how you're trying to achieve", "author": "agg3l", "date": "26 mins ago"}], "all_answer": []}}